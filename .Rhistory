set.seed(1128)
customer_folds <- vfold_cv(customer_train, v = 5, strata = exited)
# create pca df, converting binary variables into continuous
# remove geography because cannot be converted into ordinal values
customer2 <- customer %>%
mutate(
has_cr_card = if_else(has_cr_card == "1", 1, 0),
is_active_member = if_else(is_active_member == "1", 1, 0),
gender = if_else(gender == "Female", 0, 1),
exited = if_else(exited == "1", 1, 0)) %>%
select(-geography)
pca_recipe <- recipe(exited ~ ., data = customer2) |>
step_normalize(all_numeric_predictors()) |>
step_pca(all_predictors(), threshold = .75)
customer_prep_pca <- prep(pca_recipe, training = customer2)
customer_pca <- bake(customer_prep_pca, customer2) %>%
mutate(
exited = factor(exited),
geography = customer$geography)
# View the results
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "cumulative percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
geom_hline(yintercept = 75, linetype = "dashed") +
labs(x = "Component", y = "Cumulative Percent Variance")
library("tidyverse"); theme_set(theme_minimal())
# View the results
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "cumulative percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
geom_hline(yintercept = 75, linetype = "dashed") +
labs(x = "Component", y = "Cumulative Percent Variance")
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "percent variance")
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
labs(x = "Component", y = "Percent Variance Explained")
# View the results
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "cumulative percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
geom_hline(yintercept = 75, linetype = "dashed") +
labs(x = "Component", y = "Cumulative Percent Variance")
dat <- read_csv("CustomerChurn.csv")
dat <- dat[,-c(1,2)]
summary(dat)
glimpse(dat)
cust_r <- cor(dat[,-c(1,2,4,5)])
cust_r <- cor(dat[,-c(1,2,4,5)])
set.seed(1124)
dim(cust_dat)
pca_df <- cust_dat[,-c(2,3,8,9)]
# View the results
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "cumulative percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
geom_hline(yintercept = 75, linetype = "dashed") +
labs(x = "Component", y = "Cumulative Percent Variance")
# View the results
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "cumulative percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
geom_hline(yintercept = 75, linetype = "dashed") +
labs(x = "Component", title = "Cumulative Percent Variance", y = "")
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "cumulative percent variance")
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "cumulative percent variance")
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
labs(x = "Component", y = "Percent Variance Explained")
pca_split <- customer_pca |> initial_split(prop = .75, strata = exited)
pca_train <- pca_split |> training()
customer_pca <- bake(customer_prep_pca, customer2) %>%
mutate(
exited = factor(exited))
set.seed(1128)
pca_split <- customer_pca %>% initial_split(prop = .75, strata = exited)
pca_train <- pca_split %>% training()
pca_test <- pca_split %>% testing()
pca_folds <- vfold_cv(pca_train, v = 5)
set.seed(1128)
pca_split <- customer_pca %>% initial_split(prop = .75, strata = exited)
pca_train <- pca_split %>% training()
pca_test <- pca_split %>% testing()
pca_folds <- vfold_cv(pca_train, v = 5)
rf_spec <- rand_forest(trees = 500,
mtry = tune(),
min_n = tune()) %>%
set_engine("ranger") %>%
set_mode("classification")
rf_pca_rec <- recipe(exited ~ ., data = pca_train) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
rf_tuning_grid <- grid_regular(
mtry(range = c(2, 4)),
min_n(range = c(40, 50)),
levels = 10)
rf_pca_tune_results <- tune_grid(
object = workflow() %>%
add_recipe(rf_pca_rec) %>%
add_model(rf_spec),
resamples = pca_folds,
grid = rf_tuning_grid,
metrics = metric_set(accuracy))
rf_pca_best_params <- select_best(rf_pca_tune_results, "accuracy")
rf_pca_best_params
rf_pca_final <- finalize_workflow(
workflow() %>%
add_recipe(rf_pca_rec) %>%
add_model(rf_spec),
best_params) %>%
fit(data = pca_train)
rf_pca_final <- finalize_workflow(
workflow() %>%
add_recipe(rf_pca_rec) %>%
add_model(rf_spec),
rf_pca_best_params) %>%
fit(data = pca_train)
predictions <- augment(pca_rf_final, new_data = pca_test)
predictions <- augment(rf_pca_final, new_data = pca_test)
predictions <- augment(rf_pca_final, new_data = pca_test)
metrics(predictions, truth = exited, estimate = .pred_class)
customer_pca <- bake(customer_prep_pca, customer2) %>%
mutate(
exited = factor(exited),
geography = customer$geography)
set.seed(1128)
pca_split <- customer_pca %>% initial_split(prop = .75, strata = exited)
pca_train <- pca_split %>% training()
pca_test <- pca_split %>% testing()
pca_folds <- vfold_cv(pca_train, v = 5)
rf_spec <- rand_forest(trees = 500,
mtry = tune(),
min_n = tune()) %>%
set_engine("randomforest", importance = TRUE) %>%
set_mode("classification")
rf_spec <- rand_forest(trees = 500,
mtry = tune(),
min_n = tune()) %>%
set_engine("randomForest", importance = TRUE) %>%
set_mode("classification")
rf_pca_rec <- recipe(exited ~ ., data = pca_train) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
rf_tuning_grid <- grid_regular(
mtry(range = c(4, 5)),
min_n(range = c(40, 45)),
levels = 10)
rf_spec <- rand_forest(trees = 50,
mtry = tune(),
min_n = tune()) %>%
set_engine("randomForest", importance = TRUE) %>%
set_mode("classification")
rf_pca_rec <- recipe(exited ~ ., data = pca_train) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
rf_tuning_grid <- grid_regular(
mtry(range = c(4, 5)),
min_n(range = c(40, 45)),
levels = 10)
rf_pca_tune_results <- tune_grid(
object = workflow() %>%
add_recipe(rf_pca_rec) %>%
add_model(rf_spec),
resamples = pca_folds,
grid = rf_tuning_grid,
metrics = metric_set(accuracy))
rf_pca_best_params <- select_best(rf_pca_tune_results, "accuracy")
rf_pca_best_params
rf_pca_final <- finalize_workflow(
workflow() %>%
add_recipe(rf_pca_rec) %>%
add_model(rf_spec),
rf_pca_best_params) %>%
fit(data = pca_train)
rf_spec <- rand_forest(trees = 500,
mtry = tune(),
min_n = tune()) %>%
set_engine("randomForest", importance = TRUE) %>%
set_mode("classification")
rf_pca_rec <- recipe(exited ~ ., data = pca_train) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
rf_tuning_grid <- grid_regular(
mtry(range = c(3, 5)),
min_n(range = c(40, 50)),
levels = 10)
rf_pca_tune_results <- tune_grid(
object = workflow() %>%
add_recipe(rf_pca_rec) %>%
add_model(rf_spec),
resamples = pca_folds,
grid = rf_tuning_grid,
metrics = metric_set(accuracy))
rf_pca_best_params <- select_best(rf_pca_tune_results, "accuracy")
rf_pca_best_params
rf_pca_final <- finalize_workflow(
workflow() %>%
add_recipe(rf_pca_rec) %>%
add_model(rf_spec),
rf_pca_best_params) %>%
fit(data = pca_train)
predictions <- augment(rf_pca_final, new_data = pca_test)
metrics(predictions, truth = exited, estimate = .pred_class)
conf_mat(predictions, truth = exited, estimate = .pred_class)
metrics(predictions, truth = exited, estimate = .pred_class) %>%
flextable() %>%
align(align = "center") %>%
colformat_double(j = 3, digits = 4)
library("flextable")
metrics(predictions, truth = exited, estimate = .pred_class) %>%
flextable() %>%
align(align = "center") %>%
colformat_double(j = 3, digits = 4)
conf_mat(predictions, truth = exited, estimate = .pred_class)
146/(364+146)
146/(76+146)
vip(rf_pca_final)
library("vip")
vip(rf_pca_final)
library("tidyverse"); theme_set(theme_minimal())
library("tidymodels")
library("janitor")
library("xgboost")
library("vip")
library("flextable")
set_flextable_defaults(
font.size = 10, theme_fun = theme_apa,
padding = 6,
background.color = "#EFEFEF")
?corrplot
summary(customer)
customer <- read_csv("CustomerChurn.csv") %>%
clean_names() %>%
select(-customer_id, -surname) %>%
mutate(
exited = factor(exited),
has_cr_card = factor(has_cr_card),
is_active_member = factor(is_active_member)) %>%
na.omit()
customer_split <- initial_split(customer, prop = .75, strata = exited)
customer_train <- training(customer_split)
customer_test <- testing(customer_split)
# cross validation folds
set.seed(1128)
customer_folds <- vfold_cv(customer_train, v = 5, strata = exited)
# split data
set.seed(1128)
customer_split <- initial_split(customer, prop = .75, strata = exited)
customer_train <- training(customer_split)
customer_test <- testing(customer_split)
# cross validation folds
customer_folds <- vfold_cv(customer_train, v = 5, strata = exited)
summary(customer)
colSums(is.na(dat))
colSums(is.na(customer))
count(dat, Exited)
count(customer, exited)
count(customer, exited) %>%
flextable()
count(customer, exited) %>%
flextable() %>%
align(align = "center")
summary(customer)
rf_spec <- rand_forest(trees = 100,
mtry = tune(),
min_n = tune()) %>%
set_engine("ranger") %>%
set_mode("classification")
recipe <- recipe(exited ~ ., data = customer_train) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
#specify the tuning grid
tuning_grid <- grid_regular(
mtry(range = c(3, 6)),
min_n(range = c(40, 50)),
levels = 10
)
#specify the tuning grid
tuning_grid <- grid_regular(
mtry(range = c(3, 6)),
min_n(range = c(40, 50)),
levels = 10
)
#fine tune the model
tune_results <- tune_grid(
object = workflow() %>%
add_recipe(recipe) %>%
add_model(rf_spec),
resamples = customer_folds,
grid = tuning_grid,
metrics = metric_set(accuracy)
)
rf_best_params <- select_best(tune_results, "accuracy")
rf_best_params
pred_train <- predict(fitted_model, customer_train) %>%
bind_cols(customer_train)
pred_train <- predict(rf_fitted_model, customer_train) %>%
bind_cols(customer_train)
rf_fitted_model <- finalize_workflow(
workflow() %>%
add_recipe(rf_recipe) %>%
add_model(rf_spec),
rf_best_params) %>%
fit(data = customer_train)
rf_recipe <- recipe(exited ~ ., data = customer_train) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
rf_fitted_model <- finalize_workflow(
workflow() %>%
add_recipe(rf_recipe) %>%
add_model(rf_spec),
rf_best_params) %>%
fit(data = customer_train)
pred_train <- predict(rf_fitted_model, customer_train) %>%
bind_cols(customer_train)
train_metrics <- metrics(pred_train, truth = exited, estimate = .pred_class)
train_conf_mat <- conf_mat(pred_train, truth = exited, estimate = .pred_class)
print(train_metrics)
print(train_conf_mat)
predictions <- predict(rf_fitted_model, customer_test) %>%
bind_cols(customer_test)
test_metrics <- metrics(predictions, truth = exited, estimate = .pred_class)
test_conf_mat <- conf_mat(predictions, truth = exited, estimate = .pred_class)
print(test_metrics)
print(test_conf_mat)
print(test_metrics)
print(train_metrics)
dim(customer)
pca_df <- cust_dat[,-c(2,3,8,9)]
pca_df <- customer[,-c(2,3,8,9)]
dim(pca_df)
customer_pca <- princomp(pca_df[,-7], cor =T)
summary(customer_pca, loadings = T)
# create pca df, converting binary variables into continuous
# remove geography because cannot be converted into ordinal values
customer2 <- customer %>%
mutate(
has_cr_card = if_else(has_cr_card == "1", 1, 0),
is_active_member = if_else(is_active_member == "1", 1, 0),
gender = if_else(gender == "Female", 0, 1),
exited = if_else(exited == "1", 1, 0)) %>%
select(-geography)
summary(customer2, loadings = T)
customer_pca <- princomp(customer2, cor =T)
summary(customer_pca, loadings = T)
customer_pca <- customer2 %>% select(-exited) %>% princomp(cor =T)
summary(customer_pca, loadings = T)
screeplot(customer_pca)
# View the results
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "cumulative percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
geom_hline(yintercept = 75, linetype = "dashed") +
labs(x = "Component", title = "Cumulative Percent Variance", y = "")
pca_recipe <- recipe(exited ~ ., data = customer2) |>
step_normalize(all_numeric_predictors()) |>
step_pca(all_predictors(), threshold = .75)
customer_prep_pca <- prep(pca_recipe, training = customer2)
customer_pca <- bake(customer_prep_pca, customer2) %>%
mutate(
exited = factor(exited),
geography = customer$geography)
# View the results
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "cumulative percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
geom_hline(yintercept = 75, linetype = "dashed") +
labs(x = "Component", title = "Cumulative Percent Variance", y = "")
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
labs(x = "Component", y = "Percent Variance Explained")
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
labs(x = "Component", y = "Percent Variance Explained") %>%
scale_y_continuous(scales::percent)
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
labs(x = "Component", y = "Percent Variance Explained") %>%
?scale_y_continuous()
?scale_y_continuous()
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
labs(x = "Component", y = "Percent Variance Explained") %>%
scale_y_continuous(labels = scales::label_percent)
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
labs(x = "Component", y = "Percent Variance Explained") +
scale_y_continuous(labels = scales::label_percent)
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "percent variance") %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
labs(x = "Component", y = "Percent Variance Explained") +
scale_y_continuous(labels = scales::label_percent())
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "percent variance")
tidy(customer_prep_pca, number = 2, type = "variance") %>%
filter(terms == "percent variance") %>%
mutate(value = value/100) %>%
ggplot() +
geom_line(aes(x = component, y = value)) +
scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +
labs(x = "Component", y = "Percent Variance Explained") +
scale_y_continuous(labels = scales::label_percent())
vip(rf_fitted_model)
rf_spec <- rand_forest(trees = 100,
mtry = tune(),
min_n = tune()) %>%
set_engine("ranger", importance = TRUE) %>%
set_mode("classification")
rf_recipe <- recipe(exited ~ ., data = customer_train) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
#specify the tuning grid
rf_tuning_grid <- grid_regular(
mtry(range = c(3, 6)),
min_n(range = c(40, 50)),
levels = 10
)
#fine tune the model
rf_tune_results <- tune_grid(
object = workflow() %>%
add_recipe(rf_recipe) %>%
add_model(rf_spec),
resamples = customer_folds,
grid = rf_tuning_grid,
metrics = metric_set(accuracy)
)
rf_spec <- rand_forest(trees = 100,
mtry = tune(),
min_n = tune()) %>%
set_engine("randomforest", importance = TRUE) %>%
set_mode("classification")
rf_spec <- rand_forest(trees = 100,
mtry = tune(),
min_n = tune()) %>%
set_engine("randomForest", importance = TRUE) %>%
set_mode("classification")
rf_recipe <- recipe(exited ~ ., data = customer_train) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
#specify the tuning grid
rf_tuning_grid <- grid_regular(
mtry(range = c(3, 6)),
min_n(range = c(40, 50)),
levels = 10
)
#fine tune the model
rf_tune_results <- tune_grid(
object = workflow() %>%
add_recipe(rf_recipe) %>%
add_model(rf_spec),
resamples = customer_folds,
grid = rf_tuning_grid,
metrics = metric_set(accuracy)
)
vip(rf_fitted_model)
rf_best_params <- select_best(rf_tune_results, "accuracy")
rf_best_params
rf_fitted_model <- finalize_workflow(
workflow() %>%
add_recipe(rf_recipe) %>%
add_model(rf_spec),
rf_best_params) %>%
fit(data = customer_train)
vip(rf_fitted_model)
metrics(predictions, truth = exited, estimate = .pred_class) %>%
flextable() %>%
align(align = "center") %>%
colformat_double(j = 3, digits = 4)
customer %>% glimpse()
test_metrics
test_metrics %>% flextable() %>% align(align = "center")
151/222
